{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJjnhOLDmjH2"
   },
   "source": [
    "# My project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 12393,
     "status": "ok",
     "timestamp": 1632683772579,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "qsEynPSV4FKf",
    "outputId": "b0a602e6-abbd-497a-ad9d-abbac38a65ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdflib.namespace import Namespace, RDF, RDFS, XSD\n",
    "from rdflib.term import URIRef, Literal\n",
    "import csv\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "from collections import defaultdict, Counter\n",
    "import locale\n",
    "_ = locale.setlocale(locale.LC_ALL, '')\n",
    "from _plotly_future_ import v4_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "#NER\n",
    "from transformers import pipeline, set_seed\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import create_optimizer\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "import tensorflow as tf\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "import editdistance\n",
    "import difflib\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "# Embeddings\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53nBQpYb37bw"
   },
   "source": [
    "## 1. Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBCtW2krgAxV"
   },
   "source": [
    "### 1.1 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139148,
     "status": "ok",
     "timestamp": 1632681991550,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "lJqbjO9D4TcN",
    "outputId": "49fe0321-0ef5-4324-d56a-8aba54913547"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ndb1131e851864c7e80d934780e6f9593 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = rdflib.Graph()\n",
    "graph.parse('./dataset/14_graph.nt', format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBNRtXqbb0GN"
   },
   "source": [
    "### 1.2 Graph Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1632682133729,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "7KQagm9qcEFN"
   },
   "outputs": [],
   "source": [
    "# prefixes used in the graph\n",
    "WD = Namespace('http://www.wikidata.org/entity/')\n",
    "WDT = Namespace('http://www.wikidata.org/prop/direct/')\n",
    "SCHEMA = Namespace('http://schema.org/')\n",
    "DDIS = Namespace('http://ddis.ch/atai/')\n",
    "\n",
    "IMDB = Namespace('https://www.imdb.com/name/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-saved P values for Wikidata movies graph\n",
    "global P_values, Q_values\n",
    "P_values = {\n",
    "    'director':'P57',\n",
    "    'cast':'P161',\n",
    "    'producer':'P162',\n",
    "    'genre':'P136',\n",
    "    'character':'P674',\n",
    "    'screenwriter':'P58',   \n",
    "    'filming location':'P915',\n",
    "    'IMDB Id':'P345',\n",
    "    'image':'P18',\n",
    "    'publication date': 'P577',\n",
    "    'MPA film rating' : 'P1657',\n",
    "    'logo image' : 'P154',\n",
    "    'country of origin' : 'P495',\n",
    "    'cast member': 'P161',\n",
    "    'film editor' : 'P1040',\n",
    "    'production designer': 'P2554',\n",
    "    'costume designer' : 'P2515',\n",
    "    'composer' : 'P86',\n",
    "    'producer' : 'P162',\n",
    "    'distributed by' : 'P750',\n",
    "    'production company': 'P272',\n",
    "    'box office' : 'P2142',\n",
    "    'review score' : 'P444',\n",
    "    'nominated for' : 'P1411',\n",
    "    \n",
    "    \n",
    "    'sex or gender': 'P21',\n",
    "    'country of citizenship' : 'P27',\n",
    "    'name in native language':'P1559',\n",
    "    'birth name' : 'P1477',\n",
    "    'date of birth':'P569',\n",
    "    'place of birth':'P19',\n",
    "    'father':'P22',\n",
    "    'mother':'P25',\n",
    "    'sibling':'P3373',\n",
    "    'spouse':'P26',\n",
    "    'child':'P40',\n",
    "    'occupation':'P106',\n",
    "    \n",
    "}\n",
    "\n",
    "Q_values = {\n",
    "    'fictional human':'Q15632617',\n",
    "    'film':'Q11424',\n",
    "    'human':'Q5',\n",
    "#     'Wikidata property for items about films':'Q22965162',\n",
    "#     'Wikidata property related to creative works' : 'Q18618644',\n",
    "    'Wikidata property related to movies and television shows' : 'Q107395292',\n",
    "    'Wikidata property for items about people' : 'Q18608871',\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbvSdhD3d3M1"
   },
   "source": [
    "### 1.3 External Resource Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 5533,
     "status": "ok",
     "timestamp": 1632682466047,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "ZqeAnA7scSLX",
    "outputId": "081c756b-63e8-4cf1-c1d0-c676a2da31fa"
   },
   "outputs": [],
   "source": [
    "\n",
    "top250 = set(open('../dataset/imdb-top-250.t').read().split('\\n')) - {''}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPK1SDy_eScM"
   },
   "source": [
    "### 1.4 Literal Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1632684321965,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "1E8tkGhIkZ93"
   },
   "outputs": [],
   "source": [
    "roots = {\n",
    "    WD['Q8242']:        'literature',\n",
    "    WD['Q5']:           'human',\n",
    "    WD['Q483394']:      'genre',\n",
    "    WD['Q95074']:       'character',\n",
    "    WD['Q11424']:       'film',\n",
    "    WD['Q15416']:       'tv',\n",
    "    WD['Q618779']:      'award',\n",
    "    WD['Q27096213']:    'geographic',\n",
    "    WD['Q43229']:       'organisation',\n",
    "    WD['Q34770']:       'language',\n",
    "    WD['Q7725310']:     'series',\n",
    "    WD['Q47461344']:    'written work',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9xzeSuXk5eK"
   },
   "source": [
    "## 3. SPARQL query examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P57 - director of film  <br>\n",
    "P31 - instance of <br> \n",
    "subclass of (P279) <br\n",
    "\n",
    "Q11424 - film <br>\n",
    "animated feature film (Q29168811) <br>\n",
    "anime film (Q20650540) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.wikidata.org/entity/P1657\n",
      "http://www.wikidata.org/entity/Q134773\n",
      "http://www.wikidata.org/entity/Q59692464\n",
      "http://www.wikidata.org/prop/direct/P57\n"
     ]
    }
   ],
   "source": [
    "def find_entity_given_label(entity_label, entity_type=\"none\"):\n",
    "    \n",
    "    entity_label = \"\\\"\" + str(entity_label) + \"\\\"@en\"\n",
    "    \n",
    "    if entity_type == 'film':\n",
    "        entity_type = 'Q11424'\n",
    "    elif entity_type == 'human':\n",
    "        entity_type = 'Q5'\n",
    "    \n",
    "  \n",
    "    if entity_type == \"none\":\n",
    "        query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "        PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "        PREFIX schema: <http://schema.org/> \n",
    "\n",
    "        SELECT ?entity WHERE {{\n",
    "            ?entity rdfs:label {}\n",
    "        }} \"\"\".format(entity_label)\n",
    "    else:\n",
    "        query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "        PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "        PREFIX schema: <http://schema.org/> \n",
    "\n",
    "        SELECT ?entity WHERE {{\n",
    "            ?entity rdfs:label {} .\n",
    "            ?entity wdt:P31/wdt:P279* wd:{} .\n",
    "        }} \"\"\".format(entity_label, entity_type)\n",
    "        \n",
    "    \n",
    "#     print(query_content)\n",
    "    res =  list(graph.query(query_content))\n",
    "    if len(res)>0:\n",
    "        return res[0][0]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "print(find_entity_given_label(\"MPAA film rating\") )\n",
    "\n",
    "\n",
    "print(find_entity_given_label(\"Forrest Gump\",'film') )\n",
    "print(find_entity_given_label(\"Weathering with You\",'Q11424') )\n",
    "print(find_entity_given_label(\"director\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX ddis: <http://ddis.ch/atai/> \n",
      "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
      "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
      "    PREFIX schema: <http://schema.org/> \n",
      "    \n",
      "    SELECT ?answer WHERE {\n",
      "     ?movie rdfs:label \"Forrest Gump\"@en .\n",
      "     ?movie wdt:P31/wdt:P279* wd:Q11424 .\n",
      "     ?movie wdt:P57 ?answer\n",
      "    } \n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q187364'),)\n"
     ]
    }
   ],
   "source": [
    "def query_something_about_movie(p_val, label):\n",
    "    \n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "    PREFIX schema: <http://schema.org/> \n",
    "    \n",
    "    SELECT ?answer WHERE {{\n",
    "     ?movie rdfs:label \"{}\"@en .\n",
    "     ?movie wdt:P31/wdt:P279* wd:Q11424 .\n",
    "     ?movie wdt:{} ?answer\n",
    "    }} \"\"\".format(label, p_val)\n",
    "    \n",
    "    print(query_content)\n",
    "    return list(graph.query(query_content))\n",
    "      \n",
    "a = query_something_about_movie(P_values['director'], 'Forrest Gump' )    \n",
    "  \n",
    "for i in a:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX ddis: <http://ddis.ch/atai/> \n",
      "                        PREFIX wd: <http://www.wikidata.org/entity/> \n",
      "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
      "                        PREFIX schema: <http://schema.org/> \n",
      "\n",
      "                        SELECT ?label WHERE {\n",
      "                         <http://www.wikidata.org/entity/Q187364> rdfs:label ?label .\n",
      "                         \n",
      "                        } \n",
      "(rdflib.term.Literal('Robert Zemeckis', lang='en'),)\n"
     ]
    }
   ],
   "source": [
    "def get_label_of_Qval(q_val):\n",
    "    \n",
    "    query_content =  \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "                        PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "                        PREFIX schema: <http://schema.org/> \n",
    "\n",
    "                        SELECT ?label WHERE {{\n",
    "                         <{}> rdfs:label ?label .\n",
    "                         \n",
    "                        }} \"\"\".format(q_val)\n",
    "    \n",
    "    print(query_content)\n",
    "    return list(graph.query(query_content))\n",
    "\n",
    "a = get_label_of_Qval('http://www.wikidata.org/entity/Q187364')\n",
    "  \n",
    "for i in a:\n",
    "    print(i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.wikidata.org/entity/Q187364\n",
      "Robert Zemeckis\n"
     ]
    }
   ],
   "source": [
    "def find_something_about_an_entity(entity_URI, relation_URI):\n",
    "    \n",
    "   \n",
    "    \n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "    PREFIX schema: <http://schema.org/> \n",
    "    \n",
    "    SELECT ?res ?label WHERE {{\n",
    "        <{}> <{}> ?res .\n",
    "        ?res rdfs:label ?label .\n",
    "        \n",
    "    }} \"\"\".format(entity_URI, relation_URI)\n",
    "    \n",
    "\n",
    "    res =  list(graph.query(query_content))\n",
    "\n",
    "    if len(res) > 0:\n",
    "        return res[0][0], res[0][1] \n",
    "    else:\n",
    "        return -1, -1\n",
    "a, b = find_something_about_an_entity('http://www.wikidata.org/entity/Q134773','http://www.wikidata.org/prop/direct/P57') \n",
    "\n",
    "# for elements in a[0]:\n",
    "#     print(elements)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27816\n",
      "['Jan Dara', 'Moondram Pirai', \"Buffalo Bill and the Indians, or Sitting Bull's History Lesson\", 'What We Wanted', 'Wanted: Dead or Alive']\n"
     ]
    }
   ],
   "source": [
    "def write_list_to_file(list_name, file_name):\n",
    "    with open(file_name, 'w', encoding=\"utf-8\") as filehandle:\n",
    "        for listitem in list_name:\n",
    "            filehandle.write(f'{listitem}\\n')\n",
    "        \n",
    "def read_list_from_file(file_name):\n",
    "    res_list = []\n",
    "    with open(file_name, 'r', encoding=\"utf-8\") as filehandle:\n",
    "        for line in filehandle:\n",
    "            curr_place = line[:-1]\n",
    "            res_list.append(curr_place)\n",
    "    return res_list\n",
    "\n",
    "def save_file_with_all_movies(write_file_pathname):\n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "    PREFIX schema: <http://schema.org/> \n",
    "    \n",
    "    SELECT ?label WHERE {{\n",
    "        ?movie rdfs:label ?label .\n",
    "        ?movie wdt:P31/wdt:P279* wd:Q11424 .\n",
    "        \n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    res = list(graph.query(query_content))\n",
    "    res_list = []\n",
    "    for i in res:\n",
    "        res_list.append(str(i[0]))\n",
    "    write_list_to_file(res_list, write_file_pathname)\n",
    "    \n",
    "save_file_with_all_movies(\"save_files/all_movies_list.txt\")\n",
    "\n",
    "movies_list = []\n",
    "movies_list = read_list_from_file(\"save_files/all_movies_list.txt\")\n",
    "#24384\n",
    "print(len(movies_list))\n",
    "print(movies_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100157\n",
      "['Viktor Krištof', 'Yuji Nomi', 'Béatrice Thiriet', 'Oleg Kapanets', 'Ram Lee']\n"
     ]
    }
   ],
   "source": [
    "def save_file_with_all_humans(write_file_pathname):\n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "    PREFIX schema: <http://schema.org/> \n",
    "    \n",
    "    SELECT ?label WHERE {{\n",
    "        ?person rdfs:label ?label .\n",
    "        ?person wdt:P31/wdt:P279* wd:Q5 .\n",
    "        \n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    res = list(graph.query(query_content))\n",
    "    res_list = []\n",
    "    for i in res:\n",
    "        res_list.append(str(i[0]))\n",
    "    write_list_to_file(res_list, write_file_pathname)\n",
    "    \n",
    "save_file_with_all_humans(\"save_files/all_humans_list.txt\")\n",
    "humans_list = []\n",
    "humans_list = read_list_from_file(\"save_files/all_humans_list.txt\")\n",
    "#100157\n",
    "print(len(humans_list))\n",
    "print(humans_list[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q107395292 - Our KG does not have these entities, but the actual Wikidata does, all_properties_list.json is result of this same query from wikidata\n",
    "def save_file_with_all_movies_and_tv_shows_properties(write_file_pathname):\n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "        PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "        PREFIX schema: <http://schema.org/> \n",
    "\n",
    "        SELECT ?label ?entity WHERE {{\n",
    "            ?entity rdfs:label ?label .\n",
    "            ?entity wdt:P31/wdt:P279* wd:Q107395292 .\n",
    "        \n",
    "        filter (lang(?label) = \"en\")\n",
    "\n",
    "        }}\n",
    "        LIMIT 20\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "    res = list(graph.query(query_content))\n",
    "    print(res)\n",
    "    res_list = []\n",
    "    for i in res:\n",
    "        res_list.append(str(i[0]))\n",
    "    write_list_to_file(res_list, write_file_pathname)\n",
    "        \n",
    "# save_file_with_all_movies_and_tv_shows_properties(\"save_files/all_properties_list.txt\")\n",
    "# properties_list = []\n",
    "# properties_list = read_list_from_file(\"save_files/all_properties_list.txt\")\n",
    "# #100157\n",
    "# print(len(properties_list))\n",
    "# print(properties_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'res': \"Buffalo Bill and the Indians, or Sitting Bull's History Lesson\", 'res_ind': 2, 'score': 0.6067415730337079}\n",
      "{'res': 'Béatrice Thiriet', 'res_ind': 2, 'score': 0.9375}\n",
      "{'res': 'Triple Threat', 'res_ind': 10650, 'score': 0.6206896551724138}\n"
     ]
    }
   ],
   "source": [
    "def string_similarity_score(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def subtract_strings(input_str, substring):\n",
    "    output_string = \"\"\n",
    "    str_list = input_str.split(substring)\n",
    "    for element in str_list:\n",
    "        output_string += element\n",
    "    return output_string\n",
    "\n",
    "def find_closest_match_in_a_List(word, target_list):\n",
    "    res = difflib.get_close_matches(word.lower(), [item.lower() for item in target_list], n=1, cutoff = 0.6)\n",
    "    res_ind = -1\n",
    "    \n",
    "    if len(res)!=0:\n",
    "        for i in range(len(target_list)):\n",
    "            if (target_list[i].lower()) == res[0]:\n",
    "                res_ind = i\n",
    "                res = target_list[i]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "#     print(res)\n",
    "#     print(res_ind)\n",
    "    return {'res':res, 'res_ind':res_ind, 'score' :string_similarity_score(word, res) }\n",
    "print(find_closest_match_in_a_List('BuffaloBill and the Indians', movies_list))\n",
    "print(find_closest_match_in_a_List('Beatrice Thiriet', humans_list))\n",
    "print(find_closest_match_in_a_List('Beatrice Thiriet', movies_list))\n",
    "\n",
    "\n",
    "\n",
    "# print(subtract_strings(questions_df[1]['query'],questions_df[1]['ner'][0]['word']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n",
      "501\n",
      "{'label': 'GECD film ID', 'entity': 'P3367'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('save_files/all_movie_properties_list.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "all_movie_properties_list = json.load(f)\n",
    "\n",
    "\n",
    "for i,item in enumerate(all_movie_properties_list):\n",
    "    all_movie_properties_list[i]['entity'] = subtract_strings(all_movie_properties_list[i]['entity'],'http://www.wikidata.org/entity/' )\n",
    "    P_values[all_movie_properties_list[i]['label']] = all_movie_properties_list[i]['entity']\n",
    "\n",
    "print(len(P_values))\n",
    "print(len(all_movie_properties_list))\n",
    "print(all_movie_properties_list[10] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdflib.term.URIRef('http://www.wikidata.org/prop/direct/P1657')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_list = list(P_values.keys())\n",
    "final_relation_res = find_closest_match_in_a_List('MPA film rating', relation_list)\n",
    "p_val = P_values[final_relation_res['res']]\n",
    "rdflib.term.URIRef(WDT[p_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdflib.term.URIRef('http://www.wikidata.org/entity/Q134773')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_entity_given_label('Forrest Gump', Q_values['film'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = [\"Who is the director of Good Will Hunting?\", \"Who directed The Bridge on the River Kwai?\", \n",
    "                    \"Who is the director of Star Wars: Episode VI - Return of the Jedi?\", \"Who is the screenwriter of The Masked Gang: Cyprus?\",\n",
    "                    \"What is the MPAA film rating of Weathering with You?\", \"What is the genre of Good Neighbors?\", \"Show me a picture of Halle Berry.\",\n",
    "                    \"What does Julia Roberts look like?\", \"Let me know what Sandra Bullock looks like.\", \"Recommend movies similar to Hamlet and Othello.\",\n",
    "                    \"Given that I like The Lion King, Pocahontas, and The Beauty and the Beast, can you recommend some movies?\",\n",
    "                    \"Recommend movies like Nightmare on Elm Street, Friday the 13th, and Halloween.\",\n",
    "                    \"Can you tell me the publication date of Tom Meets Zizou?\", \"Who is the executive producer of X-Men: First Class?\",\n",
    "                    \"Who is the director of Batman 1989?\", \"What is the box office of The Princess and the Frog?\",\n",
    "                   \"What is the birthplace of Christopher Nolan?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Who is the director of Good Will Hunting?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who directed The Bridge on the River Kwai?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who is the director of Star Wars: Episode VI - Return of the Jedi?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who is the screenwriter of The Masked Gang: Cyprus?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'What is the MPAA film rating of Weathering with You?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'What is the genre of Good Neighbors?', 'type': '', 'entity': []},\n",
       " {'query': 'Show me a picture of Halle Berry.', 'type': '', 'entity': []},\n",
       " {'query': 'What does Julia Roberts look like?', 'type': '', 'entity': []},\n",
       " {'query': 'Let me know what Sandra Bullock looks like.',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Recommend movies similar to Hamlet and Othello.',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Given that I like The Lion King, Pocahontas, and The Beauty and the Beast, can you recommend some movies?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Recommend movies like Nightmare on Elm Street, Friday the 13th, and Halloween.',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Can you tell me the publication date of Tom Meets Zizou?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who is the executive producer of X-Men: First Class?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who is the director of Batman 1989?', 'type': '', 'entity': []},\n",
       " {'query': 'What is the box office of The Princess and the Frog?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'What is the birthplace of Christopher Nolan?',\n",
       "  'type': '',\n",
       "  'entity': []}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df = [{\"query\": s, \"type\" : \"\", \"entity\":[]}for s in sample_questions]\n",
    "questions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Entity Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "\n",
    "ner_pipeline = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.99671656,\n",
       "  'word': 'The Princess and the Frog',\n",
       "  'start': 25,\n",
       "  'end': 51}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipeline(sample_questions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'MISC', 'word': 'The Man Who Copied'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_data = []\n",
    "for movie in movies_list:\n",
    "    dummy = {\"label\":'MISC', 'word':movie}\n",
    "    fine_tune_data.append(dummy)\n",
    "    \n",
    "fine_tune_data[100]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer_POS = AutoTokenizer.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
    "model_POS = model = AutoModelForTokenClassification.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the MPAA film rating of Weathering with You?',\n",
       " 'type': '',\n",
       " 'entity': [],\n",
       " 'pos': [{'entity_group': 'PRON',\n",
       "   'score': 0.9991217,\n",
       "   'word': 'what',\n",
       "   'start': 0,\n",
       "   'end': 4},\n",
       "  {'entity_group': 'AUX',\n",
       "   'score': 0.99638736,\n",
       "   'word': 'is',\n",
       "   'start': 5,\n",
       "   'end': 7},\n",
       "  {'entity_group': 'DET',\n",
       "   'score': 0.99949145,\n",
       "   'word': 'the',\n",
       "   'start': 8,\n",
       "   'end': 11},\n",
       "  {'entity_group': 'PROPN',\n",
       "   'score': 0.9596777,\n",
       "   'word': 'mpaa',\n",
       "   'start': 12,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'NOUN',\n",
       "   'score': 0.9975196,\n",
       "   'word': 'film rating',\n",
       "   'start': 17,\n",
       "   'end': 28},\n",
       "  {'entity_group': 'ADP',\n",
       "   'score': 0.93028975,\n",
       "   'word': 'of',\n",
       "   'start': 29,\n",
       "   'end': 31},\n",
       "  {'entity_group': 'VERB',\n",
       "   'score': 0.958319,\n",
       "   'word': 'weathering',\n",
       "   'start': 32,\n",
       "   'end': 42},\n",
       "  {'entity_group': 'ADP',\n",
       "   'score': 0.9970561,\n",
       "   'word': 'with',\n",
       "   'start': 43,\n",
       "   'end': 47},\n",
       "  {'entity_group': 'PRON',\n",
       "   'score': 0.99925786,\n",
       "   'word': 'you',\n",
       "   'start': 48,\n",
       "   'end': 51},\n",
       "  {'entity_group': 'PUNCT',\n",
       "   'score': 0.99965227,\n",
       "   'word': '?',\n",
       "   'start': 51,\n",
       "   'end': 52}],\n",
       " 'ner': [{'entity_group': 'ORG',\n",
       "   'score': 0.9493264,\n",
       "   'word': 'MPAA',\n",
       "   'start': 11,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'MISC',\n",
       "   'score': 0.96832675,\n",
       "   'word': 'Weathering with You?',\n",
       "   'start': 31,\n",
       "   'end': 52}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Replace this with your own checkpoint\"\n",
    "pos_tagging_pipe = pipeline(\n",
    "    \"token-classification\", model=model_POS, aggregation_strategy=\"simple\", tokenizer = tokenizer_POS\n",
    ")\n",
    "\n",
    "# POS tagging for all of the questions\n",
    "for i in range (len(questions_df)):\n",
    "    questions_df[i][\"pos\"] = pos_tagging_pipe(questions_df[i][\"query\"])\n",
    "    questions_df[i][\"ner\"] = ner_pipeline(questions_df[i][\"query\"])\n",
    "    for j,ner_res in enumerate(questions_df[i][\"ner\"]):\n",
    "        if ner_res['score'] < 0.55:\n",
    "            del questions_df[i][\"ner\"][j]\n",
    "            print('deleted')\n",
    "questions_df[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'MISC', 'score': 0.9957466, 'word': 'Good Will Hunting', 'start': 22, 'end': 40}]\n",
      "[{'entity_group': 'LOC', 'score': 0.8970907, 'word': 'The Bridge on the River Kwai', 'start': 12, 'end': 41}]\n",
      "[{'entity_group': 'MISC', 'score': 0.99650544, 'word': 'Star Wars: Episode VI - Return of the Jedi', 'start': 22, 'end': 65}]\n",
      "[{'entity_group': 'MISC', 'score': 0.9925139, 'word': 'The Masked Gang: Cyprus', 'start': 26, 'end': 50}]\n",
      "[{'entity_group': 'ORG', 'score': 0.9493264, 'word': 'MPAA', 'start': 11, 'end': 16}, {'entity_group': 'MISC', 'score': 0.96832675, 'word': 'Weathering with You?', 'start': 31, 'end': 52}]\n",
      "[{'entity_group': 'MISC', 'score': 0.9957307, 'word': 'Good Neighbors', 'start': 20, 'end': 35}]\n",
      "[{'entity_group': 'PER', 'score': 0.9893521, 'word': 'Halle Berry', 'start': 20, 'end': 32}]\n",
      "[{'entity_group': 'PER', 'score': 0.99877614, 'word': 'Julia Roberts', 'start': 9, 'end': 23}]\n",
      "[{'entity_group': 'PER', 'score': 0.9949758, 'word': 'Sandra Bullock', 'start': 16, 'end': 31}]\n",
      "[{'entity_group': 'MISC', 'score': 0.9917609, 'word': 'Hamlet', 'start': 27, 'end': 34}, {'entity_group': 'MISC', 'score': 0.99305373, 'word': 'Othello', 'start': 38, 'end': 46}]\n",
      "[{'entity_group': 'MISC', 'score': 0.99565524, 'word': 'The Lion King', 'start': 17, 'end': 31}, {'entity_group': 'MISC', 'score': 0.98818064, 'word': 'Pocahontas', 'start': 32, 'end': 43}, {'entity_group': 'MISC', 'score': 0.9961798, 'word': 'The Beauty and the Beast', 'start': 48, 'end': 73}]\n",
      "[{'entity_group': 'MISC', 'score': 0.996117, 'word': 'Nightmare on Elm Street', 'start': 21, 'end': 45}, {'entity_group': 'MISC', 'score': 0.9939605, 'word': 'Friday the 13th', 'start': 46, 'end': 62}, {'entity_group': 'MISC', 'score': 0.9909978, 'word': 'Halloween', 'start': 67, 'end': 77}]\n",
      "[{'entity_group': 'MISC', 'score': 0.99326515, 'word': 'Tom Meets Zizou', 'start': 39, 'end': 55}]\n",
      "[{'entity_group': 'ORG', 'score': 0.71764326, 'word': 'X-Men', 'start': 32, 'end': 38}, {'entity_group': 'MISC', 'score': 0.97630614, 'word': ': First Class', 'start': 38, 'end': 51}]\n",
      "[{'entity_group': 'PER', 'score': 0.5557957, 'word': 'Batman', 'start': 22, 'end': 29}]\n",
      "[{'entity_group': 'MISC', 'score': 0.99671656, 'word': 'The Princess and the Frog', 'start': 25, 'end': 51}]\n",
      "[{'entity_group': 'PER', 'score': 0.99767727, 'word': 'Christopher Nolan', 'start': 25, 'end': 43}]\n"
     ]
    }
   ],
   "source": [
    "for i in questions_df:\n",
    "    print(i['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'res': 'Paa', 'res_ind': 20448, 'score': 0.2857142857142857}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_match_in_a_List('Weathering with You?', movies_list)\n",
    "find_closest_match_in_a_List('MPAA', movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the type of question by keyword matching\n",
    "# Can use calssifier for this\n",
    "def find_type(formulated_question_df):\n",
    "    keywords_images = [ 'image', 'picture', 'look', 'looks' ]\n",
    "    keywords_recommendation = ['similar', 'recommend', 'recommendations']\n",
    "    res_type = ''\n",
    "    query_list = []\n",
    "    for i in formulated_question_df['pos']:\n",
    "        query_list.append(i['word']) \n",
    "    if any(word in query_list for word in keywords_images):\n",
    "        res_type = \"images\"\n",
    "    elif any(word in query_list for word in keywords_recommendation):\n",
    "        res_type = \"recommendation\"\n",
    "    else :\n",
    "        res_type = \"search\"\n",
    "            \n",
    "    return res_type\n",
    "\n",
    "# Add the type for all questions\n",
    "for i in range (len(questions_df)):\n",
    "    questions_df[i]['type'] = find_type(questions_df[i])\n",
    "    \n",
    "#     print(questions_df[i]['query']) \n",
    "#     print(questions_df[i]['type']) \n",
    "#     print(\"______\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the MPAA film rating of Weathering with You?',\n",
       " 'type': 'search',\n",
       " 'entity': [],\n",
       " 'pos': [{'entity_group': 'PRON',\n",
       "   'score': 0.9991217,\n",
       "   'word': 'what',\n",
       "   'start': 0,\n",
       "   'end': 4},\n",
       "  {'entity_group': 'AUX',\n",
       "   'score': 0.99638736,\n",
       "   'word': 'is',\n",
       "   'start': 5,\n",
       "   'end': 7},\n",
       "  {'entity_group': 'DET',\n",
       "   'score': 0.99949145,\n",
       "   'word': 'the',\n",
       "   'start': 8,\n",
       "   'end': 11},\n",
       "  {'entity_group': 'PROPN',\n",
       "   'score': 0.9596777,\n",
       "   'word': 'mpaa',\n",
       "   'start': 12,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'NOUN',\n",
       "   'score': 0.9975196,\n",
       "   'word': 'film rating',\n",
       "   'start': 17,\n",
       "   'end': 28},\n",
       "  {'entity_group': 'ADP',\n",
       "   'score': 0.93028975,\n",
       "   'word': 'of',\n",
       "   'start': 29,\n",
       "   'end': 31},\n",
       "  {'entity_group': 'VERB',\n",
       "   'score': 0.958319,\n",
       "   'word': 'weathering',\n",
       "   'start': 32,\n",
       "   'end': 42},\n",
       "  {'entity_group': 'ADP',\n",
       "   'score': 0.9970561,\n",
       "   'word': 'with',\n",
       "   'start': 43,\n",
       "   'end': 47},\n",
       "  {'entity_group': 'PRON',\n",
       "   'score': 0.99925786,\n",
       "   'word': 'you',\n",
       "   'start': 48,\n",
       "   'end': 51},\n",
       "  {'entity_group': 'PUNCT',\n",
       "   'score': 0.99965227,\n",
       "   'word': '?',\n",
       "   'start': 51,\n",
       "   'end': 52}],\n",
       " 'ner': [{'entity_group': 'ORG',\n",
       "   'score': 0.9493264,\n",
       "   'word': 'MPAA',\n",
       "   'start': 11,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'MISC',\n",
       "   'score': 0.96832675,\n",
       "   'word': 'Weathering with You?',\n",
       "   'start': 31,\n",
       "   'end': 52}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good Will Hunting']\n",
      "['The Bridge on the River Kwai']\n",
      "['Star Wars: Episode VI - Return of the Jedi']\n",
      "['The Masked Gang: Cyprus']\n",
      "['Weathering with You?']\n",
      "['Good Neighbors']\n",
      "['Halle Berry']\n",
      "['Julia Roberts']\n",
      "['Sandra Bullock']\n",
      "['Hamlet', 'Othello']\n",
      "['The Lion King', 'Pocahontas', 'The Beauty and the Beast']\n",
      "['Nightmare on Elm Street', 'Friday the 13th', 'Halloween']\n",
      "['Tom Meets Zizou']\n",
      "['X-Men: First Class']\n",
      "['Batman']\n",
      "['The Princess and the Frog']\n",
      "['Christopher Nolan']\n"
     ]
    }
   ],
   "source": [
    "# find the entity for a question of type images\n",
    "def get_entities_from_nlp_results(formulated_question_df):\n",
    "    \n",
    "    res_entites = []\n",
    "    \n",
    "    for i ,ner_res in enumerate(formulated_question_df['ner']):\n",
    "        is_entity = False\n",
    "        closest_match = {'res': '', 'res_ind': -1, 'score': 0}\n",
    "        if ner_res['entity_group'] == 'MISC' or ner_res['entity_group'] == 'LOC' or ner_res['entity_group'] == 'ORG'or ner_res['entity_group'] == 'PER':\n",
    "            movies_res = find_closest_match_in_a_List(str(ner_res['word']), movies_list)\n",
    "            if movies_res != -1:                         \n",
    "                if closest_match['score'] < movies_res['score']:\n",
    "                    closest_match = movies_res\n",
    "                    is_entity = True\n",
    "                \n",
    "            human_res = find_closest_match_in_a_List(str(ner_res['word']), humans_list)\n",
    "            if human_res != -1:                              \n",
    "                if closest_match['score'] < human_res['score']:\n",
    "                    closest_match = human_res\n",
    "                    is_entity = True\n",
    "            \n",
    "            pred_res = find_closest_match_in_a_List(str(ner_res['word']), list(P_values.keys()))\n",
    "            if pred_res != -1:                              \n",
    "                if closest_match['score'] < pred_res['score']:\n",
    "                    closest_match = pred_res\n",
    "                    is_entity = False\n",
    "            \n",
    "                \n",
    "        if is_entity and closest_match['score'] > 0.5:\n",
    "            res_entites.append(ner_res['word'])\n",
    "            \n",
    "#             del formulated_question_df['ner'][i]\n",
    "            is_entity = False            \n",
    "    \n",
    "    # handle split entity\n",
    "    \n",
    "    if len(res_entites) > 1 and formulated_question_df['type'] != 'recommendation':\n",
    "        concat = ''\n",
    "        for item in res_entites:\n",
    "            concat = concat + str(item)\n",
    "        res_entites.append(concat)\n",
    "\n",
    "        final_res = ''\n",
    "        best_score = 0\n",
    "        \n",
    "#         print(res_entites)\n",
    "        \n",
    "        for i,res in enumerate(res_entites):\n",
    "            temp = find_closest_match_in_a_List(res, movies_list)\n",
    "            if temp != -1:\n",
    "               # if scores are the similar, take the longer one\n",
    "                if temp['score'] - best_score <= 0.08:\n",
    "                    if len(temp['res']) > len(final_res):\n",
    "                        final_res = res\n",
    "                        \n",
    "                        best_score = temp['score']  \n",
    "                # if you find a better match for an entity, take that\n",
    "                elif temp['score'] > best_score:\n",
    "                    final_res = res\n",
    "                    \n",
    "                    best_score = temp['score'] \n",
    "                    \n",
    "    \n",
    "        \n",
    "        formulated_question_df['entity'] = [final_res]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        formulated_question_df['entity'] = res_entites\n",
    "\n",
    "    \n",
    "    if len(formulated_question_df['entity']) ==0:\n",
    "        return -1\n",
    "    \n",
    "    return formulated_question_df\n",
    "\n",
    "for test_q_df in questions_df:\n",
    "    test_q_df = get_entities_from_nlp_results(test_q_df)\n",
    "    print(test_q_df['entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "director\n",
      "director\n",
      "director\n",
      "screenwriter\n",
      "MPA film rating\n",
      "genre\n",
      "publication date\n",
      "executive producer\n",
      "director\n",
      "box office\n",
      "birth name\n"
     ]
    }
   ],
   "source": [
    "def get_predicate_from_nlp(formulated_question):\n",
    "    string_res = str(formulated_question['query'])\n",
    "    \n",
    "    # process on all of the words that are not entity\n",
    "    \n",
    "    for entity_res in formulated_question['entity']:\n",
    "        string_res = subtract_strings(string_res, str(entity_res))\n",
    "        \n",
    "        \n",
    "#     print(string_res)\n",
    "    pos_res = pos_tagging_pipe(string_res)\n",
    "#     print(pos_res)\n",
    "    # process on all of the words that are not the following\n",
    "    \n",
    "    other_pos_tags = ['PUNCT', 'ADP', 'DET', 'AUX', 'PRON']\n",
    "    res_list = []\n",
    "    for item in pos_res:\n",
    "        if (item['entity_group']) not in other_pos_tags:\n",
    "            res_list.append( string_res[item['start']:item['end']])\n",
    "    concat = ''\n",
    "    if len(res_list) > 1:\n",
    "        for item in res_list:\n",
    "            concat = concat + ' ' + str(item)\n",
    "        res_list.append(concat)\n",
    "#     print(res_list) \n",
    "    final_res = ''\n",
    "    best_score = 0\n",
    "    for i,res in enumerate(res_list):\n",
    "        temp = find_closest_match_in_a_List(res, list(P_values.keys()))\n",
    "        if temp != -1 :\n",
    "            if temp['score'] - best_score <= 0.08:\n",
    "                if len(temp['res']) > len(final_res):\n",
    "                    final_res = temp['res']\n",
    "                    best_score = temp['score']\n",
    "            \n",
    "            elif temp['score'] > best_score:\n",
    "                final_res = temp['res']\n",
    "                best_score = temp['score'] \n",
    "    \n",
    "        \n",
    "    return final_res\n",
    "        \n",
    "\n",
    "for i in range (len(questions_df)):\n",
    "    if questions_df[i]['type'] == 'search':\n",
    "        res = get_predicate_from_nlp(questions_df[i])\n",
    "        print(res)\n",
    "# question = questions_df[2]\n",
    "# print(question['query'])\n",
    "# print(question['entity'])\n",
    "# res = get_predicate_from_nlp(question)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity = http://www.wikidata.org/entity/Q7750525\n",
      "relation = http://www.wikidata.org/prop/direct/P58\n",
      "['The Masked Gang: Cyprus']\n",
      "Who is the screenwriter of The Masked Gang: Cyprus?\n",
      "-1\n",
      "-------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdflib.term.URIRef('http://www.wikidata.org/entity/Q457180')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_something_about_an_entity('http://www.wikidata.org/entity/Q223596', 'http://www.wikidata.org/prop/direct/P1431')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_of_dict(val, my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IMDB Id'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = get_key_of_dict('P345', P_values)\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.imdb.com/name/nm0000932\n",
      "https://www.imdb.com/name/nm0000210\n",
      "https://www.imdb.com/name/nm0000113\n"
     ]
    }
   ],
   "source": [
    "# main function to answer image questions\n",
    "def handle_image_questions(formulated_question_df):\n",
    "    if formulated_question_df['type']!='images':\n",
    "        return -1\n",
    "\n",
    "    # Can change to handle multiple entites but not necessary\n",
    "    name = formulated_question_df['entity']\n",
    "    if len(name)== -1:\n",
    "        return -1\n",
    "    name = name[0]\n",
    "       \n",
    "    final_entity_name = '' \n",
    "    best_score = 0\n",
    "    movie_res = find_closest_match_in_a_List(name, movies_list)\n",
    "    if movie_res != -1 and movie_res['score'] > best_score:\n",
    "        final_entity_name = movie_res['res']\n",
    "        best_score = movie_res['score']\n",
    "        entity_type = 'film'\n",
    "    human_res = find_closest_match_in_a_List(name, humans_list)\n",
    "    if human_res != -1 and human_res['score'] > best_score:\n",
    "        final_entity_name = human_res['res']\n",
    "        best_score = human_res['score']\n",
    "        entity_type = 'human'\n",
    "    \n",
    "\n",
    "    if len(final_entity_name) == 0:\n",
    "        final_entity_name = name\n",
    "        entity_type = 'none'\n",
    "        entity_URI = find_entity_given_label(final_entity_name, entity_type)\n",
    "    else:\n",
    "        entity_URI = find_entity_given_label(final_entity_name, Q_values[entity_type])\n",
    "\n",
    "    # Return Image\n",
    "    Imdb_ID, _ =  find_something_about_an_entity(entity_URI, WDT['P345'])\n",
    "    \n",
    "    Imdb_URI = IMDB[Imdb_ID] \n",
    "    \n",
    "    return Imdb_URI\n",
    "    \n",
    "for q in questions_df:\n",
    "    if q['type']=='images':\n",
    "        res = handle_image_questions(q)\n",
    "\n",
    "        print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Graph.subject_objects at 0x0000024FDBBC9C80>\n"
     ]
    }
   ],
   "source": [
    "a = graph.subject_objects(RDFS.label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(graph):\n",
    "    global entity_emb, relation_emb, id2ent, id2rel, label2ent, ent2id, ent2label, rel2id\n",
    "    entity_emb = np.load(os.path.join('..', 'dataset','embeddings', 'entity_embeds.npy'))\n",
    "    relation_emb = np.load(os.path.join('..', 'dataset','embeddings', 'relation_embeds.npy'))\n",
    "\n",
    "    # load the dictionaries\n",
    "    with open(os.path.join('..', 'dataset','embeddings', 'entity_ids.del'), 'r') as ifile:\n",
    "        ent2id = {rdflib.term.URIRef(ent): int(idx) for idx, ent in csv.reader(ifile, delimiter='\\t')}\n",
    "        id2ent = {v: k for k, v in ent2id.items()}\n",
    "    with open(os.path.join('..', 'dataset','embeddings', 'relation_ids.del'), 'r') as ifile:\n",
    "        rel2id = {rdflib.term.URIRef(rel): int(idx) for idx, rel in csv.reader(ifile, delimiter='\\t')}\n",
    "        id2rel = {v: k for k, v in rel2id.items()}\n",
    "\n",
    "    ent2label = {ent: str(lbl) for ent, lbl in graph.subject_objects(RDFS.label)}\n",
    "    label2ent = {lbl: ent for ent, lbl in ent2label.items()}\n",
    "\n",
    "def find_similar_entities_for_id(id, n = 4):\n",
    "\n",
    "    entity = ent2id[WD[id]] \n",
    "    \n",
    "    # compute distance with other entities\n",
    "    dist = pairwise_distances(entity_emb[entity].reshape(1, -1), entity_emb).reshape(-1)\n",
    "    best_matches = dist.argsort()\n",
    "\n",
    "    best_matches = best_matches[1:20]\n",
    "    best_matches = best_matches[1:n]\n",
    "    \n",
    "    res_list = []\n",
    "    for i,idx in enumerate(best_matches):\n",
    "        res_list.append(ent2label[id2ent[idx]])\n",
    "        \n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_embeddings(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_entities_for_multiple(entity_ids):\n",
    "\n",
    "    entities = [ent2id[WD[id]] for id in entity_ids]\n",
    "    \n",
    "    entity_embs = np.array([entity_emb[entity].reshape(1, -1) for entity in entities ])\n",
    "#     print((entity_embs.shape))\n",
    "    sum_emb = entity_embs.sum(axis=0)\n",
    "    avg_entity_embedding = sum_emb/entity_embs.shape[0]\n",
    "#     print(entity_embs.shape[0])\n",
    "#     print(avg_entity_embedding.shape)\n",
    "#     print(entity_embs[0][0])\n",
    "#     print(entity_embs[1][0])\n",
    "#     print(avg_entity_embedding[0])\n",
    "    dist = pairwise_distances(avg_entity_embedding, entity_emb).reshape(-1)\n",
    "    \n",
    "    best_matches = dist.argsort()\n",
    "\n",
    "    best_matches = best_matches[1:20]\n",
    "    \n",
    "    res_list = []\n",
    "    for i,idx in enumerate(best_matches):\n",
    "        res_list.append(ent2label[id2ent[idx]])\n",
    "        \n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q164963 - two tower\n",
    "Q102225 - HP Goblet\n",
    "Q1199283 - HP Half blood\n",
    "Q131074 - return of kings\n",
    "Q471169 - Harry met sally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Texas Chainsaw 3D',\n",
       " 'Final Destination 3',\n",
       " 'The First Purge',\n",
       " 'The Texas Chainsaw Massacre',\n",
       " 'Halloween: Resurrection',\n",
       " 'The Unborn',\n",
       " 'The Purge: Anarchy',\n",
       " 'Halloween H20: 20 Years Later',\n",
       " 'Crystal Lake Memories: The Complete History of Friday the 13th',\n",
       " 'My Bloody Valentine 3D',\n",
       " 'When a Stranger Calls',\n",
       " 'The Purge',\n",
       " 'Lights Out',\n",
       " 'Con Air',\n",
       " 'Death Proof',\n",
       " 'It: Chapter Two']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def handle_recommendation_questions(formulated_question, num_recommendations = 4):\n",
    "    question_entities = formulated_question['entity']\n",
    "    movie_names = [movie['res'] for movie in question_entities ]\n",
    "\n",
    "    for i,movie_name in enumerate(movie_names):\n",
    "\n",
    "        res = find_closest_match_in_a_List(str(movie_name), movies_list)\n",
    "\n",
    "        if res != -1:\n",
    "            movie_names[i] = res['res']\n",
    "\n",
    "    entity_names = [ find_entity_given_label(movie_name, 'film') for movie_name in movie_names]\n",
    "    \n",
    "\n",
    "    entity_q_list = [subtract_strings(entity, 'http://www.wikidata.org/entity/') for entity in entity_names]\n",
    "    \n",
    "    recommendation_label_list = find_similar_entities_for_multiple(entity_q_list)\n",
    "    \n",
    "    final_res_names = []\n",
    "    for item in recommendation_label_list:\n",
    "        if item not in movie_names:\n",
    "            final_res_names.append(item)\n",
    "    \n",
    "    \n",
    "    return final_res_names\n",
    "    \n",
    "res = handle_recommendation_questions(questions_df[11])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_embeddings_for_errors(entity,relation,query_res = -1):\n",
    "    # \"Jean Van Hamme\" entity\n",
    "    if WD[entity] in ent2id.keys():\n",
    "        head = entity_emb[ent2id[WD[entity]]]\n",
    "    else:\n",
    "        return False, False\n",
    "    # \"occupation\" relation\n",
    "    if WDT[relation]in rel2id.keys():\n",
    "        pred = relation_emb[rel2id[WDT[relation]]]\n",
    "    else:\n",
    "        return False, False\n",
    "    \n",
    "    # add vectors according to TransE scoring function.\n",
    "    lhs = head + pred\n",
    "    # compute distance to *any* entity\n",
    "    dist = pairwise_distances(lhs.reshape(1, -1), entity_emb).reshape(-1)\n",
    "    # find most plausible entities\n",
    "    most_likely = dist.argsort()\n",
    "    # compute ranks of entities\n",
    "    ranks = dist.argsort().argsort()\n",
    "    if query_res != -1:\n",
    "        res = pd.DataFrame([(str(lbl), dist[ent2id[WD[ent]]], ranks[ent2id[WD[ent]]]) for ent, lbl in query_res],\n",
    "            columns=('Occupation', 'Score', 'Rank'))\n",
    "    else:\n",
    "        res = -1\n",
    "    most_likely = pd.DataFrame([\n",
    "        (id2ent[idx][len(WD):], ent2lbl[id2ent[idx]], dist[idx], rank+1)\n",
    "        for rank, idx in enumerate(most_likely[:10])],\n",
    "        columns=('Entity', 'Label', 'Score', 'Rank'))\n",
    "    return res, most_likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q311319'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "res, most_likely = check_embeddings_for_errors('Q181803', 'P57',{('Q471402','Richard Marquand')})\n",
    "most_likely.loc[:,\"Label\"].values[0]\n",
    "most_likely.loc[:,\"Entity\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "a = False\n",
    "type_a = type(a)\n",
    "if isinstance(a, bool):\n",
    "    print(type(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that I like The Lion King, Pocahontas, and The Beauty and the Beast, can you recommend some movies?\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "test_q_df = questions_df[10]\n",
    "print(test_q_df['query'])\n",
    "res = deal_with_KG_query(test_q_df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the director of Good Will Hunting?\n",
      "entity = http://www.wikidata.org/entity/Q193835\n",
      "relation = http://www.wikidata.org/prop/direct/P57\n",
      "query_res_URI = http://www.wikidata.org/entity/Q25186\n",
      "embedding rank = 2\n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q25186'), rdflib.term.Literal('Gus Van Sant', lang='en'))\n",
      "-------\n",
      "Who directed The Bridge on the River Kwai?\n",
      "entity = http://www.wikidata.org/entity/Q188718\n",
      "relation = http://www.wikidata.org/prop/direct/P57\n",
      "query_res_URI = http://www.wikidata.org/entity/Q55260\n",
      "embedding rank = 1\n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q55260'), rdflib.term.Literal('David Lean', lang='en'))\n",
      "-------\n",
      "Who is the director of Star Wars: Episode VI - Return of the Jedi?\n",
      "entity = http://www.wikidata.org/entity/Q181803\n",
      "relation = http://www.wikidata.org/prop/direct/P57\n",
      "query_res_URI = http://www.wikidata.org/entity/Q471402\n",
      "embedding rank = 5\n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q471402'), rdflib.term.Literal('Richard Marquand', lang='en'))\n",
      "-------\n",
      "Who is the screenwriter of The Masked Gang: Cyprus?\n",
      "entity = http://www.wikidata.org/entity/Q7750525\n",
      "relation = http://www.wikidata.org/prop/direct/P58\n",
      "query_res_URI = -1\n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q5058838'), 'Cengiz Küçükayvaz')\n",
      "-------\n",
      "What is the MPAA film rating of Weathering with You?\n",
      "entity = http://www.wikidata.org/entity/Q59692464\n",
      "relation = http://www.wikidata.org/prop/direct/P1657\n",
      "query_res_URI = http://www.wikidata.org/entity/Q18665349\n",
      "embedding rank = 6\n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q18665349'), rdflib.term.Literal('NC-17', lang='en'))\n",
      "-------\n",
      "What is the genre of Good Neighbors?\n",
      "entity = http://www.wikidata.org/entity/Q3110682\n",
      "relation = http://www.wikidata.org/prop/direct/P136\n",
      "query_res_URI = http://www.wikidata.org/entity/Q1135802\n",
      "embedding rank = 33\n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q130232'), 'drama')\n",
      "-------\n",
      "Can you tell me the publication date of Tom Meets Zizou?\n",
      "entity = http://www.wikidata.org/entity/Q1410031\n",
      "relation = http://www.wikidata.org/prop/direct/P577\n",
      "query_res_URI = -1\n",
      "embedding not found\n",
      "(-1, -1)\n",
      "-------\n",
      "Who is the executive producer of X-Men: First Class?\n",
      "entity = http://www.wikidata.org/entity/Q223596\n",
      "relation = http://www.wikidata.org/prop/direct/P1431\n",
      "query_res_URI = http://www.wikidata.org/entity/Q457180\n",
      "embedding rank = 27\n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q4805527'), 'Ashley Miller')\n",
      "-------\n",
      "Who is the director of Batman 1989?\n",
      "entity = http://www.wikidata.org/entity/Q810857\n",
      "relation = http://www.wikidata.org/prop/direct/P57\n",
      "query_res_URI = http://www.wikidata.org/entity/Q2067465\n",
      "embedding rank = 5\n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q2067465'), rdflib.term.Literal('Leslie H. Martinson', lang='en'))\n",
      "-------\n",
      "What is the box office of The Princess and the Frog?\n",
      "entity = http://www.wikidata.org/entity/Q171300\n",
      "relation = http://www.wikidata.org/prop/direct/P2142\n",
      "query_res_URI = -1\n",
      "embedding not found\n",
      "(-1, -1)\n",
      "-------\n",
      "What is the birthplace of Christopher Nolan?\n",
      "entity = http://www.wikidata.org/entity/Q25191\n",
      "relation = http://www.wikidata.org/prop/direct/P1477\n",
      "query_res_URI = -1\n",
      "embedding not found\n",
      "(-1, -1)\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "def deal_with_KG_query(formulated_question):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if formulated_question['type'] != 'search':\n",
    "        return -1\n",
    "    \n",
    "    # Process Entity \n",
    "    if len(formulated_question['entity']) > 0:\n",
    "        entity = formulated_question['entity'][0]\n",
    "        \n",
    "        closest_match = {'res': '', 'res_ind': -1, 'score': 0} \n",
    "        \n",
    "        movies_res = find_closest_match_in_a_List(str(entity), movies_list)\n",
    "        if movies_res != -1:                         \n",
    "            if closest_match['score'] < movies_res['score']:\n",
    "                closest_match = movies_res\n",
    "                entity_type = 'film'\n",
    "\n",
    "        human_res = find_closest_match_in_a_List(str(entity), humans_list)\n",
    "        if human_res != -1:                              \n",
    "            if closest_match['score'] < human_res['score']:\n",
    "                closest_match = human_res\n",
    "                entity_type = 'human'\n",
    "        \n",
    "        entity = closest_match['res']\n",
    "\n",
    "\n",
    "    if entity_type == 'human' or entity_type == 'film':\n",
    "        entity_URI = find_entity_given_label(entity, Q_values[entity_type])\n",
    "    else:\n",
    "        entity_URI = find_entity_given_label(entity, 'none')\n",
    "\n",
    "    # Process Relation \n",
    "    relation = get_predicate_from_nlp(formulated_question)\n",
    "\n",
    "    if relation == -1:\n",
    "        return -1\n",
    "\n",
    "    if relation in list(P_values.keys()):\n",
    "        p_val = P_values[relation]\n",
    "        relation_URI = rdflib.term.URIRef(WDT[p_val])\n",
    "    else:\n",
    "        relation_URI = find_entity_given_label(relation)\n",
    "        if relation_URI == -1:\n",
    "            return -1\n",
    "    print(\"entity = \" + str(entity_URI))\n",
    "    print(\"relation = \" +  str(relation_URI))\n",
    "    query_res_URI, query_res_label =  find_something_about_an_entity(entity_URI, relation_URI)\n",
    "#     print(query_res_URI)\n",
    "    print('query_res_URI = ' + str(query_res_URI))\n",
    "    if query_res_URI != -1:\n",
    "        query_res_Q_val = query_res_URI[len(WD):]\n",
    "#         print(query_res_Q_val)\n",
    "        emb_res, emb_most_likely = check_embeddings_for_errors(entity_URI[len(WD):], relation_URI[len(WDT):],{(query_res_Q_val,query_res_label)})\n",
    "    else:\n",
    "        emb_res, emb_most_likely = check_embeddings_for_errors(entity_URI[len(WD):], relation_URI[len(WDT):],{('Q329737', 'butcher')})\n",
    "        if not isinstance(emb_res, bool):\n",
    "            return WD[emb_most_likely.loc[:,\"Entity\"].values[0]], emb_most_likely.loc[:,\"Label\"].values[0]\n",
    "     \n",
    "    # If entity or relation are not found in embeddings\n",
    "    if isinstance(emb_res, bool):\n",
    "        # Default return\n",
    "        print('embedding not found')\n",
    "        return query_res_URI, query_res_label\n",
    "    \n",
    "    rank = emb_res.loc[:,\"Rank\"].values[0]\n",
    "    print('embedding rank = ' + str(rank))\n",
    "    if rank <= 10:\n",
    "        return query_res_URI, query_res_label\n",
    "    else:\n",
    "        return WD[emb_most_likely.loc[:,\"Entity\"].values[0]], emb_most_likely.loc[:,\"Label\"].values[0], \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for test_q_df in questions_df:\n",
    "# test_q_df = questions_df[12]\n",
    "    if test_q_df['type'] == 'search':\n",
    "# print(test_q_df['entity'])\n",
    "        print(test_q_df['query'])\n",
    "        res = deal_with_KG_query(test_q_df)\n",
    "        print(res)\n",
    "        print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  Occupation        Score  Rank\n",
       " 0      NC-17  6555.905273     6,\n",
       "       Entity                         Label        Score  Rank\n",
       " 0  Q18665339                         PG-13  5618.707520     1\n",
       " 1  Q18665334                            PG  6026.137207     2\n",
       " 2  Q18665344                             R  6102.339355     3\n",
       " 3  Q18665330                             G  6182.666504     4\n",
       " 4  Q23660208  MPAA classification category  6464.782227     5\n",
       " 5  Q59692464           Weathering with You  6538.968262     6\n",
       " 6  Q18665349                         NC-17  6555.905273     7\n",
       " 7  Q29836837     Dombey Street Productions  6569.221680     8\n",
       " 8  Q15242622         Rectangle Productions  6598.762695     9\n",
       " 9   Q2498180         Orthodox Encyclopedia  6599.468750    10)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_embeddings_for_errors('Q59692464', 'P1657',{('Q18665349', 'NC-17')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNC2BzrVbq+mNDgGNziLFpm",
   "collapsed_sections": [],
   "name": "dataset_intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
