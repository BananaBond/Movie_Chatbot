{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJjnhOLDmjH2"
   },
   "source": [
    "# My project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 12393,
     "status": "ok",
     "timestamp": 1632683772579,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "qsEynPSV4FKf",
    "outputId": "b0a602e6-abbd-497a-ad9d-abbac38a65ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdflib.namespace import Namespace, RDF, RDFS, XSD\n",
    "from rdflib.term import URIRef, Literal\n",
    "import csv\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "from collections import defaultdict, Counter\n",
    "import locale\n",
    "_ = locale.setlocale(locale.LC_ALL, '')\n",
    "from _plotly_future_ import v4_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "#NER\n",
    "from transformers import pipeline, set_seed\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import create_optimizer\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "import tensorflow as tf\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "import editdistance\n",
    "import difflib\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53nBQpYb37bw"
   },
   "source": [
    "## 1. Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBCtW2krgAxV"
   },
   "source": [
    "### 1.1 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139148,
     "status": "ok",
     "timestamp": 1632681991550,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "lJqbjO9D4TcN",
    "outputId": "49fe0321-0ef5-4324-d56a-8aba54913547"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N7354d8ffbdfa49d79973a1c9d9b87217 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = rdflib.Graph()\n",
    "graph.parse('./dataset/14_graph.nt', format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBNRtXqbb0GN"
   },
   "source": [
    "### 1.2 Graph Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1632682133729,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "7KQagm9qcEFN"
   },
   "outputs": [],
   "source": [
    "# prefixes used in the graph\n",
    "WD = Namespace('http://www.wikidata.org/entity/')\n",
    "WDT = Namespace('http://www.wikidata.org/prop/direct/')\n",
    "SCHEMA = Namespace('http://schema.org/')\n",
    "DDIS = Namespace('http://ddis.ch/atai/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-saved P values for Wikidata movies graph\n",
    "global P_values, Q_values\n",
    "P_values = {\n",
    "    'director':'P57',\n",
    "    'cast':'P161',\n",
    "    'producer':'P162',\n",
    "    'genre':'P136',\n",
    "    'character':'P674',\n",
    "    'screenwriter':'P58',   \n",
    "    'filming location':'P915',\n",
    "    'IMDB Id':'P345',\n",
    "    'image':'P18',\n",
    "    'publication date': 'P577',\n",
    "    'MPA film rating' : 'P1657',\n",
    "    'logo image' : 'P154',\n",
    "    'country of origin' : 'P495',\n",
    "    'cast member': 'P161',\n",
    "    'film editor' : 'P1040',\n",
    "    'production designer': 'P2554',\n",
    "    'costume designer' : 'P2515',\n",
    "    'composer' : 'P86',\n",
    "    'producer' : 'P162',\n",
    "    'distributed by' : 'P750',\n",
    "    'production company': 'P272',\n",
    "    'box office' : 'P2142',\n",
    "    'review score' : 'P444',\n",
    "    'nominated for' : 'P1411',\n",
    "    \n",
    "    \n",
    "    'sex or gender': 'P21',\n",
    "    'country of citizenship' : 'P27',\n",
    "    'name in native language':'P1559',\n",
    "    'birth name' : 'P1477',\n",
    "    'date of birth':'P569',\n",
    "    'place of birth':'P19',\n",
    "    'father':'P22',\n",
    "    'mother':'P25',\n",
    "    'sibling':'P3373',\n",
    "    'spouse':'P26',\n",
    "    'child':'P40',\n",
    "    'occupation':'P106',\n",
    "    \n",
    "}\n",
    "\n",
    "Q_values = {\n",
    "    'fictional human':'Q15632617',\n",
    "    'film':'Q11424',\n",
    "    'human':'Q5',\n",
    "#     'Wikidata property for items about films':'Q22965162',\n",
    "#     'Wikidata property related to creative works' : 'Q18618644',\n",
    "    'Wikidata property related to movies and television shows' : 'Q107395292',\n",
    "    'Wikidata property for items about people' : 'Q18608871',\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbvSdhD3d3M1"
   },
   "source": [
    "### 1.3 External Resource Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 5533,
     "status": "ok",
     "timestamp": 1632682466047,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "ZqeAnA7scSLX",
    "outputId": "081c756b-63e8-4cf1-c1d0-c676a2da31fa"
   },
   "outputs": [],
   "source": [
    "\n",
    "top250 = set(open('../dataset/imdb-top-250.t').read().split('\\n')) - {''}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPK1SDy_eScM"
   },
   "source": [
    "### 1.4 Literal Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1632684321965,
     "user": {
      "displayName": "Go Friday",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257507274310331112"
     },
     "user_tz": -120
    },
    "id": "1E8tkGhIkZ93"
   },
   "outputs": [],
   "source": [
    "roots = {\n",
    "    WD['Q8242']:        'literature',\n",
    "    WD['Q5']:           'human',\n",
    "    WD['Q483394']:      'genre',\n",
    "    WD['Q95074']:       'character',\n",
    "    WD['Q11424']:       'film',\n",
    "    WD['Q15416']:       'tv',\n",
    "    WD['Q618779']:      'award',\n",
    "    WD['Q27096213']:    'geographic',\n",
    "    WD['Q43229']:       'organisation',\n",
    "    WD['Q34770']:       'language',\n",
    "    WD['Q7725310']:     'series',\n",
    "    WD['Q47461344']:    'written work',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9xzeSuXk5eK"
   },
   "source": [
    "## 3. SPARQL query examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P57 - director of film  <br>\n",
    "P31 - instance of <br> \n",
    "subclass of (P279) <br\n",
    "\n",
    "Q11424 - film <br>\n",
    "animated feature film (Q29168811) <br>\n",
    "anime film (Q20650540) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.wikidata.org/entity/P1657\n",
      "http://www.wikidata.org/entity/Q134773\n",
      "http://www.wikidata.org/entity/Q59692464\n",
      "http://www.wikidata.org/prop/direct/P57\n"
     ]
    }
   ],
   "source": [
    "def find_entity_given_label(entity_label, entity_type=\"none\"):\n",
    "    \n",
    "    entity_label = \"\\\"\" + str(entity_label) + \"\\\"@en\"\n",
    "    \n",
    "    \n",
    "  \n",
    "    if entity_type == \"none\":\n",
    "        query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "        PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "        PREFIX schema: <http://schema.org/> \n",
    "\n",
    "        SELECT ?entity WHERE {{\n",
    "            ?entity rdfs:label {}\n",
    "        }} \"\"\".format(entity_label)\n",
    "    else:\n",
    "        query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "        PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "        PREFIX schema: <http://schema.org/> \n",
    "\n",
    "        SELECT ?entity WHERE {{\n",
    "            ?entity rdfs:label {} .\n",
    "            ?entity wdt:P31/wdt:P279* wd:{} .\n",
    "        }} \"\"\".format(entity_label, entity_type)\n",
    "        \n",
    "    \n",
    "#     print(query_content)\n",
    "    res =  list(graph.query(query_content))\n",
    "    if len(res)>0:\n",
    "        return res[0][0]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "print(find_entity_given_label(\"MPAA film rating\") )\n",
    "\n",
    "\n",
    "print(find_entity_given_label(\"Forrest Gump\",'Q11424') )\n",
    "print(find_entity_given_label(\"Weathering with You\",'Q11424') )\n",
    "print(find_entity_given_label(\"director\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX ddis: <http://ddis.ch/atai/> \n",
      "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
      "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
      "    PREFIX schema: <http://schema.org/> \n",
      "    \n",
      "    SELECT ?answer WHERE {\n",
      "     ?movie rdfs:label \"Forrest Gump\"@en .\n",
      "     ?movie wdt:P31/wdt:P279* wd:Q11424 .\n",
      "     ?movie wdt:P57 ?answer\n",
      "    } \n",
      "(rdflib.term.URIRef('http://www.wikidata.org/entity/Q187364'),)\n"
     ]
    }
   ],
   "source": [
    "def query_something_about_movie(p_val, label):\n",
    "    \n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "    PREFIX schema: <http://schema.org/> \n",
    "    \n",
    "    SELECT ?answer WHERE {{\n",
    "     ?movie rdfs:label \"{}\"@en .\n",
    "     ?movie wdt:P31/wdt:P279* wd:Q11424 .\n",
    "     ?movie wdt:{} ?answer\n",
    "    }} \"\"\".format(label, p_val)\n",
    "    \n",
    "    print(query_content)\n",
    "    return list(graph.query(query_content))\n",
    "      \n",
    "a = query_something_about_movie(P_values['director'], 'Forrest Gump' )    \n",
    "  \n",
    "for i in a:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX ddis: <http://ddis.ch/atai/> \n",
      "                        PREFIX wd: <http://www.wikidata.org/entity/> \n",
      "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
      "                        PREFIX schema: <http://schema.org/> \n",
      "\n",
      "                        SELECT ?label WHERE {\n",
      "                         <http://www.wikidata.org/entity/Q187364> rdfs:label ?label .\n",
      "                         \n",
      "                        } \n",
      "(rdflib.term.Literal('Robert Zemeckis', lang='en'),)\n"
     ]
    }
   ],
   "source": [
    "def get_label_of_Qval(q_val):\n",
    "    \n",
    "    query_content =  \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "                        PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "                        PREFIX schema: <http://schema.org/> \n",
    "\n",
    "                        SELECT ?label WHERE {{\n",
    "                         <{}> rdfs:label ?label .\n",
    "                         \n",
    "                        }} \"\"\".format(q_val)\n",
    "    \n",
    "    print(query_content)\n",
    "    return list(graph.query(query_content))\n",
    "\n",
    "a = get_label_of_Qval('http://www.wikidata.org/entity/Q187364')\n",
    "  \n",
    "for i in a:\n",
    "    print(i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.wikidata.org/entity/Q187364\n"
     ]
    }
   ],
   "source": [
    "def find_something_about_an_entity(entity_URI, relation_URI):\n",
    "    \n",
    "   \n",
    "    \n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "    PREFIX schema: <http://schema.org/> \n",
    "    \n",
    "    SELECT ?res WHERE {{\n",
    "        <{}> <{}> ?res\n",
    "        \n",
    "    }} \"\"\".format(entity_URI, relation_URI)\n",
    "    \n",
    "\n",
    "    res =  list(graph.query(query_content))\n",
    "    if len(res) > 0:\n",
    "        return res[0][0]\n",
    "    else:\n",
    "        return -1\n",
    "a = find_something_about_an_entity('http://www.wikidata.org/entity/Q134773','http://www.wikidata.org/prop/direct/P57') \n",
    "\n",
    "# for elements in a[0]:\n",
    "#     print(elements)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27816\n",
      "['Jan Dara', 'Moondram Pirai', \"Buffalo Bill and the Indians, or Sitting Bull's History Lesson\", 'What We Wanted', 'Wanted: Dead or Alive']\n"
     ]
    }
   ],
   "source": [
    "def write_list_to_file(list_name, file_name):\n",
    "    with open(file_name, 'w', encoding=\"utf-8\") as filehandle:\n",
    "        for listitem in list_name:\n",
    "            filehandle.write(f'{listitem}\\n')\n",
    "        \n",
    "def read_list_from_file(file_name):\n",
    "    res_list = []\n",
    "    with open(file_name, 'r', encoding=\"utf-8\") as filehandle:\n",
    "        for line in filehandle:\n",
    "            curr_place = line[:-1]\n",
    "            res_list.append(curr_place)\n",
    "    return res_list\n",
    "\n",
    "def save_file_with_all_movies(write_file_pathname):\n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "    PREFIX schema: <http://schema.org/> \n",
    "    \n",
    "    SELECT ?label WHERE {{\n",
    "        ?movie rdfs:label ?label .\n",
    "        ?movie wdt:P31/wdt:P279* wd:Q11424 .\n",
    "        \n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    res = list(graph.query(query_content))\n",
    "    res_list = []\n",
    "    for i in res:\n",
    "        res_list.append(str(i[0]))\n",
    "    write_list_to_file(res_list, write_file_pathname)\n",
    "    \n",
    "save_file_with_all_movies(\"save_files/all_movies_list.txt\")\n",
    "\n",
    "movies_list = []\n",
    "movies_list = read_list_from_file(\"save_files/all_movies_list.txt\")\n",
    "#24384\n",
    "print(len(movies_list))\n",
    "print(movies_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100157\n",
      "['Viktor Krištof', 'Yuji Nomi', 'Béatrice Thiriet', 'Oleg Kapanets', 'Ram Lee']\n"
     ]
    }
   ],
   "source": [
    "def save_file_with_all_humans(write_file_pathname):\n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "    PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "    PREFIX schema: <http://schema.org/> \n",
    "    \n",
    "    SELECT ?label WHERE {{\n",
    "        ?person rdfs:label ?label .\n",
    "        ?person wdt:P31/wdt:P279* wd:Q5 .\n",
    "        \n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    res = list(graph.query(query_content))\n",
    "    res_list = []\n",
    "    for i in res:\n",
    "        res_list.append(str(i[0]))\n",
    "    write_list_to_file(res_list, write_file_pathname)\n",
    "    \n",
    "save_file_with_all_humans(\"save_files/all_humans_list.txt\")\n",
    "humans_list = []\n",
    "humans_list = read_list_from_file(\"save_files/all_humans_list.txt\")\n",
    "#100157\n",
    "print(len(humans_list))\n",
    "print(humans_list[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q107395292 - Our KG does not have these entities, but the actual Wikidata does, all_properties_list.json is result of this same query from wikidata\n",
    "def save_file_with_all_movies_and_tv_shows_properties(write_file_pathname):\n",
    "    query_content = \"\"\"PREFIX ddis: <http://ddis.ch/atai/> \n",
    "        PREFIX wd: <http://www.wikidata.org/entity/> \n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/> \n",
    "        PREFIX schema: <http://schema.org/> \n",
    "\n",
    "        SELECT ?label ?entity WHERE {{\n",
    "            ?entity rdfs:label ?label .\n",
    "            ?entity wdt:P31/wdt:P279* wd:Q107395292 .\n",
    "        \n",
    "        filter (lang(?label) = \"en\")\n",
    "\n",
    "        }}\n",
    "        LIMIT 20\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "    res = list(graph.query(query_content))\n",
    "    print(res)\n",
    "    res_list = []\n",
    "    for i in res:\n",
    "        res_list.append(str(i[0]))\n",
    "    write_list_to_file(res_list, write_file_pathname)\n",
    "        \n",
    "# save_file_with_all_movies_and_tv_shows_properties(\"save_files/all_properties_list.txt\")\n",
    "# properties_list = []\n",
    "# properties_list = read_list_from_file(\"save_files/all_properties_list.txt\")\n",
    "# #100157\n",
    "# print(len(properties_list))\n",
    "# print(properties_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'res': \"Buffalo Bill and the Indians, or Sitting Bull's History Lesson\", 'res_ind': 2, 'score': 0.6067415730337079}\n",
      "{'res': 'Béatrice Thiriet', 'res_ind': 2, 'score': 0.9375}\n",
      "{'res': 'Triple Threat', 'res_ind': 10650, 'score': 0.6206896551724138}\n"
     ]
    }
   ],
   "source": [
    "def string_similarity_score(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def subtract_strings(input_str, substring):\n",
    "    output_string = \"\"\n",
    "    str_list = input_str.split(substring)\n",
    "    for element in str_list:\n",
    "        output_string += element\n",
    "    return output_string\n",
    "\n",
    "def find_closest_match_in_a_List(word, target_list):\n",
    "    res = difflib.get_close_matches(word.lower(), [item.lower() for item in target_list], n=1, cutoff = 0.6)\n",
    "    res_ind = -1\n",
    "    \n",
    "    if len(res)!=0:\n",
    "        for i in range(len(target_list)):\n",
    "            if (target_list[i].lower()) == res[0]:\n",
    "                res_ind = i\n",
    "                res = target_list[i]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "#     print(res)\n",
    "#     print(res_ind)\n",
    "    return {'res':res, 'res_ind':res_ind, 'score' :string_similarity_score(word, res) }\n",
    "print(find_closest_match_in_a_List('BuffaloBill and the Indians', movies_list))\n",
    "print(find_closest_match_in_a_List('Beatrice Thiriet', humans_list))\n",
    "print(find_closest_match_in_a_List('Beatrice Thiriet', movies_list))\n",
    "\n",
    "\n",
    "\n",
    "# print(subtract_strings(questions_df[1]['query'],questions_df[1]['ner'][0]['word']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P345'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('all_movie_properties_list.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "all_movie_properties_list = json.load(f)\n",
    "\n",
    "len(all_movie_properties_list)\n",
    "\n",
    "for item in all_movie_properties_list:\n",
    "    P_values[item['label']] = subtract_strings(item['entity'],'http://www.wikidata.org/entity/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'director': 'P57', 'cast': 'P161', 'producer': 'P162', 'genre': 'P136', 'character': 'P674', 'screenwriter': 'P58', 'filming location': 'P915', 'IMDB Id': 'P345', 'image': 'P18', 'publication date': 'P577', 'MPA film rating': 'P1657', 'logo image': 'P154', 'country of origin': 'P495', 'cast member': 'P161', 'film editor': 'P1040', 'production designer': 'P2554', 'costume designer': 'P2515', 'composer': 'P86', 'distributed by': 'P750', 'production company': 'P272', 'box office': 'P2142', 'review score': 'P444', 'nominated for': 'P1411', 'sex or gender': 'P21', 'country of citizenship': 'P27', 'name in native language': 'P1559', 'birth name': 'P1477', 'date of birth': 'P569', 'place of birth': 'P19', 'father': 'P22', 'mother': 'P25', 'sibling': 'P3373', 'spouse': 'P26', 'child': 'P40', 'occupation': 'P106', 'test_key': 'test_val'}\n"
     ]
    }
   ],
   "source": [
    "print(len(P_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdflib.term.URIRef('http://www.wikidata.org/prop/direct/P1657')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_list = list(P_values.keys())\n",
    "final_relation_res = find_closest_match_in_a_List('MPA film rating', relation_list)\n",
    "p_val = P_values[final_relation_res['res']]\n",
    "rdflib.term.URIRef(WDT[p_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdflib.term.URIRef('http://www.wikidata.org/entity/Q134773')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_entity_given_label('Forrest Gump', Q_values['film'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = [\"Who is the director of Good Will Hunting?\", \"Who directed The Bridge on the River Kwai?\", \n",
    "                    \"Who is the director of Star Wars: Episode VI - Return of the Jedi?\", \"Who is the screenwriter of The Masked Gang: Cyprus?\",\n",
    "                    \"What is the MPAA film rating of Weathering with You?\", \"What is the genre of Good Neighbors?\", \"Show me a picture of Halle Berry.\",\n",
    "                    \"What does Julia Roberts look like?\", \"Let me know what Sandra Bullock looks like.\", \"Recommend movies similar to Hamlet and Othello.\",\n",
    "                    \"Given that I like The Lion King, Pocahontas, and The Beauty and the Beast, can you recommend some movies?\",\n",
    "                    \"Recommend movies like Nightmare on Elm Street, Friday the 13th, and Halloween.\",\n",
    "                    \"Can you tell me the publication date of Tom Meets Zizou?\", \"Who is the executive producer of X-Men: First Class?\",\n",
    "                    \"Who is the director of Batman 1989?\", \"What is the box office of The Princess and the Frog?\",\n",
    "                   \"What is the birthplace of Christopher Nolan?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Who is the director of Good Will Hunting?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who directed The Bridge on the River Kwai?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who is the director of Star Wars: Episode VI - Return of the Jedi?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who is the screenwriter of The Masked Gang: Cyprus?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'What is the MPAA film rating of Weathering with You?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'What is the genre of Good Neighbors?', 'type': '', 'entity': []},\n",
       " {'query': 'Show me a picture of Halle Berry.', 'type': '', 'entity': []},\n",
       " {'query': 'What does Julia Roberts look like?', 'type': '', 'entity': []},\n",
       " {'query': 'Let me know what Sandra Bullock looks like.',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Recommend movies similar to Hamlet and Othello.',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Given that I like The Lion King, Pocahontas, and The Beauty and the Beast, can you recommend some movies?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Recommend movies like Nightmare on Elm Street, Friday the 13th, and Halloween.',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Can you tell me the publication date of Tom Meets Zizou?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who is the executive producer of X-Men: First Class?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'Who is the director of Batman 1989?', 'type': '', 'entity': []},\n",
       " {'query': 'What is the box office of The Princess and the Frog?',\n",
       "  'type': '',\n",
       "  'entity': []},\n",
       " {'query': 'What is the birthplace of Christopher Nolan?',\n",
       "  'type': '',\n",
       "  'entity': []}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df = [{\"query\": s, \"type\" : \"\", \"entity\":[]}for s in sample_questions]\n",
    "questions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Entity Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "\n",
    "ner_pipeline = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.99671656,\n",
       "  'word': 'The Princess and the Frog',\n",
       "  'start': 25,\n",
       "  'end': 51}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipeline(sample_questions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'MISC', 'word': 'The Man Who Copied'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_data = []\n",
    "for movie in movies_list:\n",
    "    dummy = {\"label\":'MISC', 'word':movie}\n",
    "    fine_tune_data.append(dummy)\n",
    "    \n",
    "fine_tune_data[100]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer_POS = AutoTokenizer.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
    "model_POS = model = AutoModelForTokenClassification.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the MPAA film rating of Weathering with You?',\n",
       " 'type': '',\n",
       " 'entity': [],\n",
       " 'pos': [{'entity_group': 'PRON',\n",
       "   'score': 0.9991217,\n",
       "   'word': 'what',\n",
       "   'start': 0,\n",
       "   'end': 4},\n",
       "  {'entity_group': 'AUX',\n",
       "   'score': 0.99638736,\n",
       "   'word': 'is',\n",
       "   'start': 5,\n",
       "   'end': 7},\n",
       "  {'entity_group': 'DET',\n",
       "   'score': 0.99949145,\n",
       "   'word': 'the',\n",
       "   'start': 8,\n",
       "   'end': 11},\n",
       "  {'entity_group': 'PROPN',\n",
       "   'score': 0.9596777,\n",
       "   'word': 'mpaa',\n",
       "   'start': 12,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'NOUN',\n",
       "   'score': 0.9975196,\n",
       "   'word': 'film rating',\n",
       "   'start': 17,\n",
       "   'end': 28},\n",
       "  {'entity_group': 'ADP',\n",
       "   'score': 0.93028975,\n",
       "   'word': 'of',\n",
       "   'start': 29,\n",
       "   'end': 31},\n",
       "  {'entity_group': 'VERB',\n",
       "   'score': 0.958319,\n",
       "   'word': 'weathering',\n",
       "   'start': 32,\n",
       "   'end': 42},\n",
       "  {'entity_group': 'ADP',\n",
       "   'score': 0.9970561,\n",
       "   'word': 'with',\n",
       "   'start': 43,\n",
       "   'end': 47},\n",
       "  {'entity_group': 'PRON',\n",
       "   'score': 0.99925786,\n",
       "   'word': 'you',\n",
       "   'start': 48,\n",
       "   'end': 51},\n",
       "  {'entity_group': 'PUNCT',\n",
       "   'score': 0.99965227,\n",
       "   'word': '?',\n",
       "   'start': 51,\n",
       "   'end': 52}],\n",
       " 'ner': [{'entity_group': 'ORG',\n",
       "   'score': 0.9493264,\n",
       "   'word': 'MPAA',\n",
       "   'start': 11,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'MISC',\n",
       "   'score': 0.96832675,\n",
       "   'word': 'Weathering with You?',\n",
       "   'start': 31,\n",
       "   'end': 52}]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Replace this with your own checkpoint\"\n",
    "pos_tagging_pipe = pipeline(\n",
    "    \"token-classification\", model=model_POS, aggregation_strategy=\"simple\", tokenizer = tokenizer_POS\n",
    ")\n",
    "\n",
    "# POS tagging for all of the questions\n",
    "for i in range (len(questions_df)):\n",
    "    questions_df[i][\"pos\"] = pos_tagging_pipe(questions_df[i][\"query\"])\n",
    "    questions_df[i][\"ner\"] = ner_pipeline(questions_df[i][\"query\"])\n",
    "    for j,ner_res in enumerate(questions_df[i][\"ner\"]):\n",
    "        if ner_res['score'] < 0.55:\n",
    "            del questions_df[i][\"ner\"][j]\n",
    "            print('deleted')\n",
    "questions_df[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'MISC', 'score': 0.9957466, 'word': 'Good Will Hunting', 'start': 22, 'end': 40}]\n",
      "[{'entity_group': 'LOC', 'score': 0.8970907, 'word': 'The Bridge on the River Kwai', 'start': 12, 'end': 41}]\n",
      "[{'entity_group': 'MISC', 'score': 0.99650544, 'word': 'Star Wars: Episode VI - Return of the Jedi', 'start': 22, 'end': 65}]\n",
      "[{'entity_group': 'MISC', 'score': 0.9925139, 'word': 'The Masked Gang: Cyprus', 'start': 26, 'end': 50}]\n",
      "[{'entity_group': 'ORG', 'score': 0.9493264, 'word': 'MPAA', 'start': 11, 'end': 16}, {'entity_group': 'MISC', 'score': 0.96832675, 'word': 'Weathering with You?', 'start': 31, 'end': 52}]\n",
      "[{'entity_group': 'MISC', 'score': 0.9957307, 'word': 'Good Neighbors', 'start': 20, 'end': 35}]\n",
      "[{'entity_group': 'PER', 'score': 0.9893521, 'word': 'Halle Berry', 'start': 20, 'end': 32}]\n",
      "[{'entity_group': 'PER', 'score': 0.99877614, 'word': 'Julia Roberts', 'start': 9, 'end': 23}]\n",
      "[{'entity_group': 'PER', 'score': 0.9949758, 'word': 'Sandra Bullock', 'start': 16, 'end': 31}]\n",
      "[{'entity_group': 'MISC', 'score': 0.9917609, 'word': 'Hamlet', 'start': 27, 'end': 34}, {'entity_group': 'MISC', 'score': 0.99305373, 'word': 'Othello', 'start': 38, 'end': 46}]\n",
      "[{'entity_group': 'MISC', 'score': 0.99565524, 'word': 'The Lion King', 'start': 17, 'end': 31}, {'entity_group': 'MISC', 'score': 0.98818064, 'word': 'Pocahontas', 'start': 32, 'end': 43}, {'entity_group': 'MISC', 'score': 0.9961798, 'word': 'The Beauty and the Beast', 'start': 48, 'end': 73}]\n",
      "[{'entity_group': 'MISC', 'score': 0.996117, 'word': 'Nightmare on Elm Street', 'start': 21, 'end': 45}, {'entity_group': 'MISC', 'score': 0.9939605, 'word': 'Friday the 13th', 'start': 46, 'end': 62}, {'entity_group': 'MISC', 'score': 0.9909978, 'word': 'Halloween', 'start': 67, 'end': 77}]\n",
      "[{'entity_group': 'MISC', 'score': 0.99326515, 'word': 'Tom Meets Zizou', 'start': 39, 'end': 55}]\n",
      "[{'entity_group': 'ORG', 'score': 0.71764326, 'word': 'X-Men', 'start': 32, 'end': 38}, {'entity_group': 'MISC', 'score': 0.97630614, 'word': ': First Class', 'start': 38, 'end': 51}]\n",
      "[{'entity_group': 'PER', 'score': 0.5557957, 'word': 'Batman', 'start': 22, 'end': 29}]\n",
      "[{'entity_group': 'MISC', 'score': 0.99671656, 'word': 'The Princess and the Frog', 'start': 25, 'end': 51}]\n",
      "[{'entity_group': 'PER', 'score': 0.99767727, 'word': 'Christopher Nolan', 'start': 25, 'end': 43}]\n"
     ]
    }
   ],
   "source": [
    "for i in questions_df:\n",
    "    print(i['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'res': 'Paa', 'res_ind': 20448, 'score': 0.2857142857142857}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_match_in_a_List('Weathering with You?', movies_list)\n",
    "find_closest_match_in_a_List('MPAA', movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the type of question by keyword matching\n",
    "# Can use calssifier for this\n",
    "def find_type(formulated_question_df):\n",
    "    keywords_images = [ 'image', 'picture', 'look', 'looks' ]\n",
    "    keywords_recommendation = ['similar', 'recommend', 'recommendations']\n",
    "    res_type = ''\n",
    "    query_list = []\n",
    "    for i in formulated_question_df['pos']:\n",
    "        query_list.append(i['word']) \n",
    "    if any(word in query_list for word in keywords_images):\n",
    "        res_type = \"images\"\n",
    "    elif any(word in query_list for word in keywords_recommendation):\n",
    "        res_type = \"recommendation\"\n",
    "    else :\n",
    "        res_type = \"search\"\n",
    "            \n",
    "    return res_type\n",
    "\n",
    "# Add the type for all questions\n",
    "for i in range (len(questions_df)):\n",
    "    questions_df[i]['type'] = find_type(questions_df[i])\n",
    "    \n",
    "#     print(questions_df[i]['query']) \n",
    "#     print(questions_df[i]['type']) \n",
    "#     print(\"______\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the MPAA film rating of Weathering with You?',\n",
       " 'type': 'search',\n",
       " 'entity': [],\n",
       " 'pos': [{'entity_group': 'PRON',\n",
       "   'score': 0.9991217,\n",
       "   'word': 'what',\n",
       "   'start': 0,\n",
       "   'end': 4},\n",
       "  {'entity_group': 'AUX',\n",
       "   'score': 0.99638736,\n",
       "   'word': 'is',\n",
       "   'start': 5,\n",
       "   'end': 7},\n",
       "  {'entity_group': 'DET',\n",
       "   'score': 0.99949145,\n",
       "   'word': 'the',\n",
       "   'start': 8,\n",
       "   'end': 11},\n",
       "  {'entity_group': 'PROPN',\n",
       "   'score': 0.9596777,\n",
       "   'word': 'mpaa',\n",
       "   'start': 12,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'NOUN',\n",
       "   'score': 0.9975196,\n",
       "   'word': 'film rating',\n",
       "   'start': 17,\n",
       "   'end': 28},\n",
       "  {'entity_group': 'ADP',\n",
       "   'score': 0.93028975,\n",
       "   'word': 'of',\n",
       "   'start': 29,\n",
       "   'end': 31},\n",
       "  {'entity_group': 'VERB',\n",
       "   'score': 0.958319,\n",
       "   'word': 'weathering',\n",
       "   'start': 32,\n",
       "   'end': 42},\n",
       "  {'entity_group': 'ADP',\n",
       "   'score': 0.9970561,\n",
       "   'word': 'with',\n",
       "   'start': 43,\n",
       "   'end': 47},\n",
       "  {'entity_group': 'PRON',\n",
       "   'score': 0.99925786,\n",
       "   'word': 'you',\n",
       "   'start': 48,\n",
       "   'end': 51},\n",
       "  {'entity_group': 'PUNCT',\n",
       "   'score': 0.99965227,\n",
       "   'word': '?',\n",
       "   'start': 51,\n",
       "   'end': 52}],\n",
       " 'ner': [{'entity_group': 'ORG',\n",
       "   'score': 0.9493264,\n",
       "   'word': 'MPAA',\n",
       "   'start': 11,\n",
       "   'end': 16},\n",
       "  {'entity_group': 'MISC',\n",
       "   'score': 0.96832675,\n",
       "   'word': 'Weathering with You?',\n",
       "   'start': 31,\n",
       "   'end': 52}]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good Will Hunting']\n",
      "['The Bridge on the River Kwai']\n",
      "['Star Wars: Episode VI - Return of the Jedi']\n",
      "['The Masked Gang: Cyprus']\n",
      "['Weathering with You?']\n",
      "['Good Neighbors']\n",
      "['Halle Berry']\n",
      "['Julia Roberts']\n",
      "['Sandra Bullock']\n",
      "['Hamlet', 'Othello']\n",
      "['The Lion King', 'Pocahontas', 'The Beauty and the Beast']\n",
      "['Nightmare on Elm Street', 'Friday the 13th', 'Halloween']\n",
      "['Tom Meets Zizou']\n",
      "['X-Men', ': First Class']\n",
      "['Batman']\n",
      "['The Princess and the Frog']\n",
      "['Christopher Nolan']\n"
     ]
    }
   ],
   "source": [
    "# find the entity for a question of type images\n",
    "def get_entities_from_nlp_results(formulated_question_df):\n",
    "\n",
    "    for i ,ner_res in enumerate(formulated_question_df['ner']):\n",
    "        is_entity = False\n",
    "        closest_match = {'res': '', 'res_ind': -1, 'score': 0}\n",
    "        if ner_res['entity_group'] == 'MISC' or ner_res['entity_group'] == 'LOC' or ner_res['entity_group'] == 'ORG'or ner_res['entity_group'] == 'PER':\n",
    "            movies_res = find_closest_match_in_a_List(str(ner_res['word']), movies_list)\n",
    "            if movies_res != -1:                         \n",
    "                if closest_match['score'] < movies_res['score']:\n",
    "                    closest_match = movies_res\n",
    "                    is_entity = True\n",
    "                \n",
    "            human_res = find_closest_match_in_a_List(str(ner_res['word']), humans_list)\n",
    "            if human_res != -1:                              \n",
    "                if closest_match['score'] < human_res['score']:\n",
    "                    closest_match = human_res\n",
    "                    is_entity = True\n",
    "            \n",
    "            pred_res = find_closest_match_in_a_List(str(ner_res['word']), list(P_values.keys()))\n",
    "            if pred_res != -1:                              \n",
    "                if closest_match['score'] < pred_res['score']:\n",
    "                    closest_match = pred_res\n",
    "                    is_entity = False\n",
    "            \n",
    "                \n",
    "        if is_entity and closest_match['score'] > 0.5:\n",
    "            formulated_question_df['entity'].append(ner_res['word'])\n",
    "#             del formulated_question_df['ner'][i]\n",
    "            is_entity = False            \n",
    "            \n",
    "    if len(formulated_question_df['entity']) ==0:\n",
    "        return -1\n",
    "    \n",
    "    return formulated_question_df\n",
    "\n",
    "for test_q_df in questions_df:\n",
    "    test_q_df = get_entities_from_nlp_results(test_q_df)\n",
    "    print(test_q_df['entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'res': 'X-Men: First Class', 'res_ind': 24226, 'score': 1.0}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = find_closest_match_in_a_List('X-Men: First Class', movies_list)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the director of ?\n",
      "director\n",
      "Who directed ?\n",
      "director\n",
      "Who is the director of ?\n",
      "director\n",
      "Who is the screenwriter of ?\n",
      "screenwriter\n",
      "What is the MPAA film rating of \n",
      "MPA film rating\n",
      "What is the genre of ?\n",
      "genre\n",
      "Can you tell me the publication date of ?\n",
      "publication date\n",
      "Who is the executive producer of ?\n",
      "producer\n",
      "Who is the director of  1989?\n",
      "director\n",
      "What is the box office of ?\n",
      "box office\n",
      "What is the birthplace of ?\n",
      "birth name\n"
     ]
    }
   ],
   "source": [
    "def get_predicate_from_nlp(formulated_question):\n",
    "    string_res = str(formulated_question['query'])\n",
    "    \n",
    "    # process on all of the words that are not entity\n",
    "    \n",
    "    for entity_res in formulated_question['entity']:\n",
    "        string_res = subtract_strings(string_res, str(entity_res))\n",
    "        \n",
    "        \n",
    "    print(string_res)\n",
    "    pos_res = pos_tagging_pipe(string_res)\n",
    "    \n",
    "    # process on all of the words that are not the following\n",
    "    \n",
    "    other_pos_tags = ['PUNCT', 'ADP', 'ADJ', 'DET', 'AUX', 'PRON']\n",
    "    res_list = []\n",
    "    for item in pos_res:\n",
    "        if (item['entity_group']) not in other_pos_tags:\n",
    "            res_list.append( item['word'])\n",
    "    \n",
    "    temp_list = []\n",
    "    ind_list = []\n",
    "    for i,res in enumerate(res_list):\n",
    "        temp = find_closest_match_in_a_List(res, list(P_values.keys()))\n",
    "        if temp != -1:\n",
    "            temp_list.append(temp)\n",
    "            ind_list.append(i)\n",
    "    \n",
    "    final_res = -1\n",
    "    if len(temp_list) != 0 :\n",
    "        final_res = temp_list[0]['res']  \n",
    "        \n",
    "    return final_res\n",
    "        \n",
    "\n",
    "for i in range (len(questions_df)):\n",
    "    if questions_df[i]['type'] == 'search':\n",
    "        res = get_predicate_from_nlp(questions_df[i])\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'res': 'place of birth', 'res_ind': 28, 'score': 0.8333333333333334}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_match_in_a_List('placebirth', list(P_values.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who directed ?\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.wikidata.org/entity/Q1135802\n",
      "http://www.wikidata.org/entity/Q18665349\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "def deal_with_KG_query(entity, relation):\n",
    "    \n",
    "    # Process Entity \n",
    "    \n",
    "    match_list = []\n",
    "    entity_type = 'none'\n",
    "    movie_res = find_closest_match_in_a_List(entity, movies_list)\n",
    "    if movie_res != -1:\n",
    "        match_list.append(movie_res['res'])\n",
    "    human_res = find_closest_match_in_a_List(entity, humans_list)\n",
    "    if human_res != -1:\n",
    "        match_list.append(human_res['res'])\n",
    "\n",
    "    final_entity_res = find_closest_match_in_a_List(entity, match_list)\n",
    "    \n",
    "    if final_entity_res == -1:\n",
    "        final_entity_res = {'res':entity, 'res_ind' : -1}\n",
    "        \n",
    "    else:\n",
    "        if human_res != -1 and (final_entity_res['res'] == human_res['res']):\n",
    "            entity_type = 'human'\n",
    "        elif movie_res != -1 and (final_entity_res['res'] == movie_res['res']):\n",
    "            entity_type = 'film'\n",
    "        \n",
    "#     print(final_entity_res['res'])\n",
    "#     print(entity_type)\n",
    "    entity_URI = find_entity_given_label(final_entity_res['res'], Q_values[entity_type])\n",
    "    \n",
    "    \n",
    "    # Process Relation \n",
    "    \n",
    "    entity_type = \"none\"\n",
    "    relation_list = list(P_values.keys())\n",
    "    \n",
    "    final_relation_res = find_closest_match_in_a_List(relation, relation_list)\n",
    "    if final_relation_res == -1:\n",
    "        final_relation_res = {'res':relation, 'res_ind' : -1,}\n",
    "#     print(final_relation_res['res'])\n",
    "#     print(entity_type)\n",
    "    if final_relation_res['res_ind'] != -1:\n",
    "        p_val = P_values[final_relation_res['res']]\n",
    "        \n",
    "        relation_URI = rdflib.term.URIRef(WDT[p_val])\n",
    "    else:\n",
    "        \n",
    "        relation_URI = find_entity_given_label(final_relation_res['res'])\n",
    "    \n",
    "#     print(relation_URI)\n",
    "#     print(entity_URI)\n",
    "    \n",
    "    return find_something_about_an_entity(entity_URI, relation_URI)\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "# res = deal_with_KG_query('Forest Gump','directed')\n",
    "# print(res)\n",
    "\n",
    "# res = deal_with_KG_query('Tom Meets Zizou','tell publication date')\n",
    "# print(res)\n",
    "\n",
    "res = deal_with_KG_query('Good Neighbors','genre')\n",
    "print(res)\n",
    "\n",
    "res = deal_with_KG_query('Weathering with You','MPA film rating')\n",
    "print(res)\n",
    "\n",
    "res = deal_with_KG_query('The Masked Gang: Cyprus','screenwriter ')\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "https://commons.wikimedia.org/wiki/File:Halle_Berry_by_Gage_Skidmore_2.jpg\n",
      "https://commons.wikimedia.org/wiki/File:Julia_Roberts_(43838880775).jpg\n",
      "https://commons.wikimedia.org/wiki/File:Sandra_Bullock,_The_Heat,_London,_2013_(crop).jpg\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# main function to answer image questions\n",
    "def handle_image_questions(formulated_question_df):\n",
    "    if formulated_question_df['type']!='images':\n",
    "        return -1\n",
    "    else:\n",
    "        # Can change to handle multiple entites but not necessary\n",
    "        name = get_entities_from_nlp_results(formulated_question_df)\n",
    "        if name == -1:\n",
    "            return -1\n",
    "        name = name[0]\n",
    "       \n",
    "        \n",
    "    match_list = []\n",
    "    entity_type = 'none'\n",
    "    movie_res = find_closest_match_in_a_List(name, movies_list)\n",
    "    if movie_res != -1:\n",
    "        match_list.append(movie_res['res'])\n",
    "    human_res = find_closest_match_in_a_List(name, humans_list)\n",
    "    if human_res != -1:\n",
    "        match_list.append(human_res['res'])\n",
    "\n",
    "    final_entity_res = find_closest_match_in_a_List(name, match_list)\n",
    "    \n",
    "    if final_entity_res == -1:\n",
    "        final_entity_res = {'res':entity, 'res_ind' : -1}\n",
    "        \n",
    "    else:\n",
    "        if (final_entity_res['res'] == human_res['res']):\n",
    "            entity_type = 'human'\n",
    "        elif (final_entity_res['res'] == movie_res['res']):\n",
    "            entity_type = 'film'\n",
    "#     print(final_entity_res['res'])\n",
    "    entity_URI = find_entity_given_label(final_entity_res['res'], Q_values[entity_type])\n",
    "    \n",
    "#     print(entity_URI)\n",
    "    \n",
    "    # Return Image\n",
    "    return find_something_about_an_entity(entity_URI, WDT['P18'])\n",
    "    \n",
    "    \n",
    "for q in questions_df:\n",
    "    res = handle_image_questions(q)\n",
    "    \n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNC2BzrVbq+mNDgGNziLFpm",
   "collapsed_sections": [],
   "name": "dataset_intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
